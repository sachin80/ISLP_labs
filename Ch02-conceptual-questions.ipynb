{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Exercises "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conceptual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1a. A more flexible model is good because $n$ is large then we have many observations. A more flexible model will have lower bias but higher variance and because you have many observations and few predictors you can afford higher variance since you have enough data to reliably estimate the model parameters and less risk of overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1b. A more flexible model is bad because $n$ is small then we have less observations. A more flexible model will risk overfitting the data since there might not be enough data points to reliably estimate all the parameters. Usually, it's better to use a less flexible model and most will resort to regularization or simplifying assumptions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1c. A more flexible model is good since an inflexible model like a linear regression will not be able to fit a non-linear relationship. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1d. A more flexible model is probably bad since the variance is already high. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2a. n = 500, p = 4. This is a regression because CEO salary is quanititative. This is an inference problem since we are interested in understanding what predictors affect the response or output. \n",
    "\n",
    "2b. n = 20, p = 13. This is a classification problem and prediction. \n",
    "\n",
    "2c. n = 52, p = 4. This is a regression problem since the percent change in USD/Euro exchange rate is a quantitative response. This is prediction problem since we are only intersted in the percent change. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Advantages for a flexible approach is that it might be better at capturing a more complex underlying pattern that is non-linear and has lower bias. As the flexibility of a model increases, understanding the contribution of each predictor becomes harder. Also, more flexible model require a lot of data. A less flexible approach is better if you don't have a lot data and the underlying function is linear. Also, they tend to be less likely to overfit. They are also more interpretable. But they have higher bias, may underfit, and be unable to capture more complex patterns.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. \n",
    "Parametric models - \n",
    "Advantages - the estimating a pattern is reduced to estimating a set of parameters since. Model tends to be simpler leadingt o more interpretability.  \n",
    "Disadvantages - may be too simple to estimate the underlying pattern. \n",
    "\n",
    "Non-parametric models - \n",
    "Advantages - makes no assumption on the underlying pattern, can fit potentially a wide variety of cases. \n",
    "Disadvatages - requires a lot more, may lead to overfitting, and less interpretable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. \n",
    "\n",
    "If we have two points $p_1 = (x_1, y_1, z_1)$ and $p_2 = (x_1, y_2, z_2)$ then the Euclidean distance is \n",
    "\n",
    "$d_{21} = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2 + (z_2 - z_1)^2}$\n",
    "\n",
    "a. \n",
    "Obs 1: 3 -> R\n",
    "Obs 2: 2 -> R\n",
    "Obs 3: 3 -> R\n",
    "Obs 4: sqrt(5) ~ 2.24 -> G\n",
    "Obs 5: sqrt(2) ~ 1.41 -> G\n",
    "Obs 6: sqrt(3) ~ 1.73 -> R\n",
    "\n",
    "b. The prediction for K = 1 is G because the new observation is closest to Obs 5 data point, which is classified as G. \n",
    "\n",
    "c. The prediction for K = 3 is R because Obs 2, Obs 5, and Obs 6 data points are closest by distance and 2/3 of the data points are R. \n",
    "\n",
    "d. If we have a highly non-linear Bayes decision bounday, then a small K would be better because his corresponds to a more flexible model and finds a decisioin boundary that has more variance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
